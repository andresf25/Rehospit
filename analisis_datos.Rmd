---
title: "<span style='color:#305f72'><center><br>Modelo de Predicción Rehospitalización</center>"
output: html_notebook
date: "<center>Abril 2019</center>"
author: "<center><a href='mailto:andres.gonzalez@datalytics.com'>Andrés Felipe González</a></center>"
---

<hr>
<table>
<tr>
<td><img style="width:280px; height:200px;" src="SURA.png" /></td>
<td><img style="width:200px; height:150px;" src="blanco.jpg" /></td>
<td><img style="width:360px; height:100px;" src="Datalytics.png" /></td>
</tr>
</table>
<hr>

<h3 id="indice" style="text-align: center;" markdown="1">Índice</h3>
<div style="text-align: justify">

El presente notebook contiene información relacionada al entendimiento de los datos y resultados obtenidos de un modelo de predicción para el problema de rehospitalización.

<ol>
    <li><a href="#Generalidades">Generalidades</a></li>
    <li><a href="#Entendimiento">Entendimiento de los datos</a></li>
    <li><a href="#Perdidos">Análisis de Registros Pérdidos</a></li>
    <li><a href="#Analisis">Análisis Exploratorio</a></li>
      <ol>
        <li><a href="#AnalisisCon">Análisis univariado - variables continuas</a></li>
        <li><a href="#AnalisisCar">Análisis univariado - variables cardinales</a></li>
      </ol>
    <li><a href="#AnalisisWOE">Análisis de clasificación binaria usando WOE y el IV</a></li>
    <li><a href="#Modelo">Modelo</a></li>
      <ol>
        <li><a href="#SMOTE">SMOTE - Balanceo de categoria minoritaria</a></li>
        <li><a href="#Ajustemod">Ajuste del modelo y Estimación de parámetros</a></li>
        <li><a href="#Evaluacion">Prediciendo y evaluando el desempeño del modelo</a></li>
      </ol>
    <li><a href="#Conclusiones">Resultados y Conclusiones</a></li>
    <li><a href="#Recomendacion">Recomendaciones y Estrategias</a></li>
</ol>

Haciendo click sobre cada una de las secciones puede ir directamente a cada una de ellas. Al finalizar cada sección encontrará un link para volver al índice.</div>
<hr>

<h3 id="Generalidades" style="text-align: center;" markdown="1">Generalidades</h3>
<div style="text-align: justify">

El objetivo es desarrollar e implementar un modelo de predicción de rehospitalizaciones para apoyar los programas de evitabilidad post-hospitalaria. El análisis se realizará con información que describe las características sociodemográficas del individuo y con algunos datos recolectados por el personal hospitalario; para un periodo de tiempo de dos años y medio, que va desde 2016 hasta 2018.

Para el análisis realizado se consideró que una rehospitalización surge al cumplirse las siguientes condiciones:
1. Que 30 dias posteriores a una primera hospitalización, el paciente dabe recurrir nuevamente a una hospitalización.
2. Que los diagnósticos tanto de la primera como de la segunda hospitalizacipon coincidan en la categoria diagnóstico de la OMS.

[Volver al Índice](#indice)</div>

```{r, message = FALSE, warning = FALSE, echo = FALSE, eval =TRUE}
rm(list = ls())
options(scipen = 100)

source("functions_plot.R")

list.of.packages <- c("readxl", "dplyr", "ggplot2", "ggcorrplot", "VIM", "RColorBrewer", "Information", "knitr", "kableExtra", "gridExtra", "skimr", "nortest", "GGally", "plotly", "lattice", "DMwR", "caTools", "plotly")

new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)

load <- lapply(list.of.packages, library, character.only = TRUE)
```

<hr>
<h3 style="text-align: center;" id="Entendimiento" markdown = "1">Entendimiento de los datos</h3>
<div style= "text-align:justify"> 

El archivo contiene registros que corresponden a eventos de rehospitalizaciones y se encuentra detallado a nivel de cada evento hospitalario. En total son 34898 registros, 18 variables, descartando de manera inicial, aquellos atributos que se derivan después del segundo diagnóstico; los datos se describen a continuación:</div>

```{r, message = FALSE, warning = FALSE, echo = FALSE, eval =TRUE}
data_rehosp <- read_xlsx("DATA_REHOSP.xlsx",na = c("na", "NA", "null", "NULL"))
data_rehosp %>%
  select(Edad_Hospitalizacion,
         Estrato_Vivienda,
         Rango_Ingresos_Desc,
         Estado_Civil,
         Genero,
         cantidad_marcas,
         Ramo_Id,
         Ciudad_Contacto_Nombre,
         Codigo_Diagnostico_Op,
         Categoria_Dx_Id,
         Quirurgico,
         Fecha_Ingreso_Hosp,
         Numero_Dias_Hospitalario,
         Numero_Dias_Uci,
         Numero_Dias_Uce,
         Proveedor,
         Valor_Pagado_Diagnostico,
         rehosp_cat_oms) %>%
  rename(edad = Edad_Hospitalizacion, 
         estrato = Estrato_Vivienda,
         ingreso = Rango_Ingresos_Desc,
         est_civil = Estado_Civil,
         genero = Genero,
         marcas = cantidad_marcas,
         ramo = Ramo_Id,
         ciudad = Ciudad_Contacto_Nombre,
         diagnos = Codigo_Diagnostico_Op,
         categoria = Categoria_Dx_Id,
         quirur = Quirurgico,
         fecha_ingreso = Fecha_Ingreso_Hosp,
         dias_hosp = Numero_Dias_Hospitalario,
         dias_uci = Numero_Dias_Uci,
         dias_uce = Numero_Dias_Uce,
         proveedor = Proveedor,
         pago_hosp = Valor_Pagado_Diagnostico,
         rehosp_oms = rehosp_cat_oms) -> data_rehosp
head(data_rehosp)
```

<ul>
<li>Variables continuas (4)
<ul>
<li>dias_hosp: días de hospitalización</li>
<li>dias_uci: número días en UCI</li>
<li>dias_uce: número días en UCE</li>
<li>pago_hosp: valor pagado primera hospitalización</li>
</ul>
</li>
</ul>
<ul>
<li>Variables nominales (5)
<ul>
<li>estrato: estrato Vivienda (0,1,2,3,4,5,6,-1)</li>
<li>est_civil: estado civil (C,D,S,U,V,-1)</li>
<li>ciudad: ciudad de contacto del asegurado</li>
<li>diagnos: código diagnóstico CIE10 de la primera atención </li>
<li>categoria: categoría del diagnóstico según el tipo de enfermedad</li>
</ul>
</li>
</ul>
<ul>
<li>Variable dicotómica (4)
<ul>
<li>genero: género del asegurado (M,F)</li>
<li>ramo: ramo al que pertenece el asegurado</li>
<li>quirur: si tuvo algun tipo de servicio relacionado a procedimiento quirúrgico</li>
<li>rehosp_cat_oms: similitud categoría cie10. Esta es nuestra variable objetivo </li>
</ul>
</li>
</ul>
<ul>
<li>Variables discretas (2)
<ul>
<li>edad: edad del asegurado en el momento de la hospitalización</li>
<li>marcas: cantidad de marcas confirmadas del asegurado</li>
</ul>
</li>
</ul>
<ul>
<li>Variables ordinales (1)
<ul>
<li>ingreso: rango de ingresos</li>
</ul>
</li>
</ul>
<ul>
<li>Fecha (1)
<ul>
<li>Fecha_Ingreso: fecha ingreso hospitalización </li>
</ul>
</li>
</ul>

<div style= "text-align:justify">
Generamos la estadística descriptiva; en ella se puede visualizar que será necesario realizar más adelante algunas conversiones en los tipos de datos que vienen por defecto (por ejemplo el estrato aparece como una variable numérica). Pero antes de continuar con la codificación, procederemos a observar como se encuentran nuestras variables.</div>

<br>

```{r, message = FALSE, warning = FALSE, echo = FALSE, eval =TRUE}
skim_with(numeric = list(hist = NULL))

data_rehosp %>% 
  group_by() %>%
  skim()
```

<ul>
<li>La variable ingreso es la que más datos perdidos tiene, seguida del estrato.
<li>La mayoría de los pacientes no estuvieron ingresados en el UCI o en UCE
<li>El pago hospitalario promedio fue de $5'706,108 con una desviación de $11'447,135 de la media, lo que indica una gran dispersión en los datos, y posible presencia de outliers.
<ul>

<br>

A continuacion veremos algunas graficas que permiten realizar inferencias acerca del comportamiento de los datos:
```{r, message = FALSE, warning = FALSE, echo = FALSE, eval =TRUE, fig.width=8, fig.height=4}
require(scales)

data_rehosp %>%
  filter(pago_hosp > 0 & quirur == 0 & rehosp_oms == 1) %>%
  group_by(fecha_ingreso) %>%
  summarise_all(~sum(pago_hosp)) %>%
    ggplot(
      aes(
        x=fecha_ingreso, 
        y=pago_hosp)) +
    geom_line(
      color = "#99CCFF", 
      size = 0.3) + 
    geom_smooth(method = "lm") + 
    theme_minimal() +
    labs(title = "Pago Hosp en el tiempo",
         x= "Fecha Ingreso",
         y = "Pago Hosp") +
    theme(plot.title = element_text(hjust = 0.5),
          legend.position = "none") + 
    scale_y_continuous(labels = dollar) -> p11

p11 <- ggplotly(p11)
p11
```

```{r, message = FALSE, warning = FALSE, echo = FALSE, eval =TRUE, fig.width=8, fig.height=4}
data_rehosp %>%
  group_by(ciudad) %>%
  summarise_all(~sum(rehosp_oms)) %>%
  filter(rehosp_oms > 8) %>%
    ggplot(
      aes(fill=ciudad,
          x=ciudad, 
          y=rehosp_oms)) +
    geom_bar(stat = "identity") + 
    theme_minimal() +
    labs(title = "Rehospitalizacion por ciudad",
         x= "Ciudad",
         y = "Cant. Rehosp") +
    theme(axis.text.x = element_text(angle = 90),
          plot.title = element_text(hjust = 0.5),
          legend.position = "none") +
    scale_fill_brewer(palette = "Blues")-> p12

p12 <- ggplotly(p12)
p12

```
```{r, message = FALSE, warning = FALSE, echo = FALSE, eval =TRUE, fig.width=8, fig.height=4}
 require(scales)
 
data_rehosp %>%
  filter(rehosp_oms > 0) %>%
  group_by(fecha_ingreso) %>%
  summarise_all(~sum(rehosp_oms)) %>%
    ggplot(
      aes(
        x=fecha_ingreso, 
        y=rehosp_oms)) +
    geom_point(color="#99CCFF", 
      size=2) + 
    geom_smooth(method = "lm") + 
    theme_minimal() +
    labs(title = "Numero Rehosp en el tiempo",
        x= "Fecha Rehosp.",
        y = "Num. Rehosp.") +
   theme(plot.title = element_text(hjust = 0.5),
         legend.position = "none") -> p13
 
p13 <- ggplotly(p13)
p13
```

[Volver al Índice](#indice)</div>

<hr>
<h2 id="Perdidos" style="text-align: center;" markdown="1">Análisis de Registros Pérdidos</h2>

En la gráfica siguiente podemos observar que hay en total 4 variables que contienen registros vacios: estrato, estado civil, ingreso y proveedor.

A nivel individual el porcentaje de valores perdidos para todos los casos es superior al 25%. De forma combinada hay más del 30% de campos vacíos; por ende no podemos decir que la probabilidad de que falte un valor depende solo del valor observado, y usar un método para imputarlo (la forma no es aleatoria).

```{r, message = FALSE, warning = FALSE, eval =TRUE, echo = FALSE}
aggr(data_rehosp,
     col = c("#CCE5FF", "#99CCFF"),
     cex.axis = 0.7,
     prop = c(TRUE, FALSE),
     number = TRUE,
     gap = 1.5,
     border = NA,
     bars = FALSE,
     ylab = c("Proporción de Datos Perdidos", "Combinaciones"))
```

<div style= "text-align:justify"></div>
Dado lo anterior, se hace necesario construir una tercera categoría, por lo menos para las variables que poseen menos campos vacíos (estrato y estado civil).

Para estimar si existe una asociación entre las variables que pueda derivarse en colinealidad, se procede primero a verificar que las variables no poseen una distribución normal, una vez realizado esto, se elige el test de Spearman para hallar la correlación lineal por atributo.</div>

```{r, message = FALSE, warning = FALSE, echo = FALSE, eval =TRUE}
data_rehosp %>%
  select(pago_hosp, 
         dias_uci,
         dias_uce,
         dias_hosp,
         rehosp_oms) -> data_num

norm_test <- lapply(data_num, lillie.test)
lres <- sapply(norm_test, `[`, c("statistic","p.value"))
t(lres)
```

<div style= "text-align:justify">
Los resultados confirman que ninguna de las variables pesenta una distribución normal y las correlaciones relacionadas a continuación, verifican posibles asociaciones entre las variables de los días en que el paciente estuvo internado en la Unidad de Cuidados Intensivos, en la Unidad de Cuidados Especiales y los días que el paciente estuvo hospitalizado. Por conocimiento de facto, la relación entre la variable "dias_uci" y "dias_uce" es entendible, ya que cuando un paciente que ha pasado por la Unidad de Cuidados Intensivos pasó su momento de crisis y su estado de salud es más estable, suele ser remitido a la Unidad de Cuidados Especiales. </div>

```{r, message = FALSE, warning = FALSE, echo = FALSE, eval =TRUE}
corr_num <- round(cor(data_num),4)
p.mat <- cor_pmat(data_num, method = "spearman")

ggcorrplot(corr_num, 
           type = "lower",
           outline.col = "white",
           p.mat = p.mat,
           sig.level = 0.05,
           ggtheme = ggplot2::theme_minimal,
           lab = TRUE,
           colors = c("#99CCFF", "white", "#0066CC")) + 
  labs(title = "Correlacion entre variables numéricas")
```

<div style= "text-align:justify"></div>
Sin embargo, las correlaciones obtenidas no cumplen un umbral suficiente para considerarlas importantes, por ende se procede a conservarlas y evaluar más adelante si es preciso eliminarlas definitivamente. Por otro lado, la variable categoría y diagnóstico están altamente correlacionadas con la variable endógena, por lo que es necesario eliminarlas del análisis, para no incurrir en posibles sobreajustes en la etapa de modelado.

Como se había mencionado anteriormente, teniendo en cuenta el análisis de datos perdidos o nulos, se decide descartar la variable ingreso ya que contiene mas de un 30% en datos perdidos.</div>

```{r, message = FALSE, warning = FALSE, echo = FALSE, eval =TRUE}

data_rehosp %>%
  mutate(estrato = ifelse(is.na(estrato) | estrato == -1 | estrato == 0, "Sin Informacion", estrato),
         est_civil = ifelse(is.na(est_civil), "Sin Informacion", est_civil),
         ingreso = ifelse(is.na(ingreso), "Sin Informacion", ingreso),
         proveedor = ifelse(is.na(proveedor), "Sin Informacion", proveedor),
         quirur = ifelse(quirur == 1, 'Si', 'No'),
         edad = case_when( edad <= 30 ~ "18-30",
                           edad >= 31 & edad <= 40 ~ "31-40",
                           edad >= 41 & edad <= 50 ~ "41-50",
                           edad >= 51 & edad <= 60 ~ "51-60",
                           edad >= 61 & edad <= 70 ~ "61-70",
                           edad >= 71 & edad <= 80 ~ "71-80",
                           edad >= 81 ~ "81+"),
         marcas = cut(marcas, breaks = (0:3)*2, include.lowest = TRUE),
         est_civil = as.factor(est_civil),
         genero = as.factor(genero),
         quirur = as.factor(quirur),
         ramo = as.factor(ramo),
         edad = as.factor(edad),
         estrato = as.factor(estrato)) %>%
  select(-diagnos, -categoria, -fecha_ingreso, -ingreso, -proveedor, -ciudad) -> data_rehosp

str(data_rehosp)
```

[Volver al Índice](#indice)</div>

<hr>
<h2 id="Analisis" style="text-align: center;" markdown="1">Análisis Exploratorio</h2>

<h3 id="AnalisisCon" style="text-align: center;"markdown="1">Análisis univariado - variables continuas</h3>
<div style="text-align: justify">

Es evidente la existencia también, de valores atípicos muy marcados tanto en el numéro de días de hospitalización, como en los números de días que el paciente estuvo en la Unidad de Cuidado Intensivos y Especiales, en dónde los valores atípicos más grandes suceden en los eventos que no desencadenaron en rehospitalización.</div>

```{r, message = FALSE, warning = FALSE, echo = FALSE, eval =TRUE}

data_rehosp %>%
  filter(dias_uci > 0) %>%
  ggplot (., aes ( dias_uci, color = as.factor(rehosp_oms))) +
  geom_histogram(fill="white", alpha=0.5, position="identity") +
  theme_minimal() +
  labs(x = "Días UCI", 
       y = "Frecuencia Relativa", 
       fill = " ") +
  ggtitle("Días en Unidad de Cuidados") +
  theme(plot.title = element_text(hjust = 0.5)) + 
    scale_colour_brewer(palette = "Paired") +
  theme(legend.position = "none") -> p1

data_rehosp %>%
  filter(dias_uce > 0) %>%
  ggplot (., aes ( dias_uce, color = as.factor(rehosp_oms))) +
  geom_histogram(fill="white", alpha=0.5, position="identity") +
  theme_minimal() +
  labs(x = "Días UCE", 
       y = "Frecuencia Relativa", 
       fill = "Rehospitalización") +
  ggtitle("Número de días en Unidad de Cuidados") +
  theme(plot.title = element_text(hjust = 0.5)) + 
    scale_colour_brewer(palette = "Paired") +
  theme(legend.position = "right") -> p2

p1 <- ggplotly(p1)
p2 <- ggplotly(p2)

subplot(p1, p2, titleX = TRUE, titleY = TRUE) %>%
  layout(showlegend = (FALSE))
```

<div style= "text-align:justify"></div>
Con el análisis anterior no sólo se logra identificar la presencia de valores atípicos, sino que también es posible evidenciar que los datos se encuentran altamente desbalanceados. En el caso de los outliers se truncará en los casos en que sea necesario, imputando los valores que superen cierto límite en el percentil, tanto mayor como menor.</div>

```{r, message = FALSE, warning = FALSE, echo = FALSE, eval =TRUE}
data_rehosp %>%
  mutate(pago_hosp = ifelse(quirur == "Si" & rehosp_oms == 0, 
                            outlier(mydata = filter(data_rehosp, quirur == "Si" & rehosp_oms == 0), 
                                    value = "pago_hosp", q_min = 0, q_max = 0.97), pago_hosp),
         pago_hosp = ifelse(quirur == "Si" & rehosp_oms == 1, 
                            outlier(mydata = filter(data_rehosp, quirur == "Si" & rehosp_oms == 1),
                                    value = "pago_hosp", q_min = 0, q_max = 0.98), pago_hosp),
         pago_hosp = ifelse(quirur == "No" & rehosp_oms == 0, 
                            outlier(mydata = filter(data_rehosp, quirur == "No" & rehosp_oms == 0),                                                      value = "pago_hosp", q_min = 0, q_max = 0.97), pago_hosp), 
         pago_hosp = ifelse(quirur == "No" & rehosp_oms == 1, 
                            outlier(mydata = filter(data_rehosp, quirur == "No" & rehosp_oms == 1), 
                                    value = "pago_hosp", q_min = 0, q_max = 0.98), pago_hosp),
         dias_hosp = ifelse(rehosp_oms == 0, 
                            outlier(mydata = filter(data_rehosp, rehosp_oms == 0), 
                                                    value = "dias_hosp", q_min = 0, q_max = 0.99),
                            outlier(mydata = filter(data_rehosp, rehosp_oms == 1), 
                                                    value = "dias_hosp", q_min = 0, q_max = 0.99)),
         dias_uci = ifelse(rehosp_oms == 0, 
                           outlier(mydata = filter(data_rehosp, rehosp_oms == 0 & dias_uci > 0), 
                                                    value = "dias_uci", q_min = 0, q_max = 0.999)
                           , dias_uci),
         dias_uce = ifelse(rehosp_oms == 0, 
                           outlier(mydata = filter(data_rehosp, rehosp_oms == 0 & dias_uce > 0), 
                                                    value = "dias_uce", q_min = 0, q_max = 0.999)
                           , dias_uci)) -> data_rehosp
```


```{r, message = FALSE, warning = FALSE, echo = FALSE, eval =TRUE}

p3 <- myboxplot(mydata = filter(data_rehosp, pago_hosp > 0), 
                myexposure = "rehosp_oms", 
                myoutcome = "pago_hosp", 
                mytitle = "Pago hospitalización", 
                mylabel_x = "", 
                mylabel_y = "Pago Diag", 
                my_fill = "")

p4 <- myboxplot(mydata = data_rehosp, 
                myexposure = "rehosp_oms", 
                myoutcome = "dias_hosp", 
                mytitle = "Total dias hospitalizado", 
                mylabel_x = "", 
                mylabel_y = "Dias hospitalización", 
                my_fill = "")

p5 <- myboxplot(mydata = filter(data_rehosp, dias_uci > 0), 
                myexposure = "rehosp_oms", 
                myoutcome = "dias_uci", 
                mytitle =  "Total días UCI", 
                mylabel_x = "", 
                mylabel_y = "Dias UCI", 
                my_fill = "")

p6 <- myboxplot(mydata = filter(data_rehosp, dias_uce > 0), 
                myexposure = "rehosp_oms", 
                myoutcome = "dias_uce", 
                mytitle = "Total días UCE", 
                mylabel_x = "", 
                mylabel_y = "Dias UCE", 
                my_fill = "")

p3 <- ggplotly(p3)
p4 <- ggplotly(p4)
p5 <- ggplotly(p5)
p6 <- ggplotly(p6)

subplot(p5, p6, p3, p4, 
        nrows = 2, ncol(2), 
        titleX = TRUE, titleY = TRUE) %>%
  layout(showlegend = (FALSE))



```

<div style= "text-align:justify"></div>
Se puede observar que en la variable días UCI, correspondiente al primer diagnóstico, no parece haber una diferencia significativa en la distribución al discriminar por la variable objetivo binaria, es decir, entre los casos de rehospitalización (1) y casos de no rehospitalización (0). Adicionalmente, la distibución en ambas variables no es simétrica. 

A pesar de que los datos se encuentran bastante dispersos, se logra identificar diferencias en la variable del pago -con valores más altos en los caso en que no terminó de buevo hospitalizado, y en el casó del número de días hospitalizado los rangos son mucho más pequeños cuando hay una rehospitalización.</div>

<hr>
<h3 id="AnalisisCar"style="text-align: center;" markdown = "1">Análisis variables categóricas</h3>
<div style="text-align: justify">

Observando las variables categóricas la diferencia entre la probabilidad de que el evento ocurra (haya rehospitalización) o no, se puede evidenciar sólo en algunas clases por categoría, pero en general, las proporciones suelen ser bastantes similares, por lo que no es posible elaborar a priori una hipótesis que estipule diferencias significativas en las distribuciones, por lo menos para ninguna de las dos variables relacionadas en el gráfico a continuación.</div>

```{r, message = FALSE, warning = FALSE, echo = FALSE, eval =TRUE}

p7 <- mygeom_bar(mydata = data_rehosp, 
                 myexposure = "edad", 
                 myoutcome = "rehosp_oms", 
                 mytitle = "Edad", 
                 mylabel_x = "", 
                 mylabel_y = "Frecuencia", 
                 my_fill = "Rehospitalización", 
                 my_angle = NULL,
                 my_legend = "right")

p8 <- mygeom_bar(mydata = data_rehosp, 
                  myexposure = "estrato", 
                  myoutcome = "rehosp_oms", 
                  mytitle = "Estrato", 
                  mylabel_x = "", 
                  mylabel_y = "Frecuencia", 
                  my_fill = "Rehospitalización", 
                  my_angle = NULL,
                  my_legend = "none")

grid.arrange(p7,
             p8)

```

<div style= "text-align:justify"></div>
Por otro lado, el atributo que indica el hecho de que se hayan realizado procedimientos quirúrgicos durante la primera hospitalización muestran cierta diferencia en la distribuión por grupo; es más probable que la persona deba ser rehospitalizada de nuevo.</div>

```{r, message = FALSE, warning = FALSE, echo = FALSE, eval =TRUE}

p9 <- mygeom_bar(mydata = data_rehosp, 
                  myexposure = "quirur", 
                  myoutcome = "rehosp_oms", 
                  mytitle = "Proc quirúrgico", 
                  mylabel_x = "", 
                  mylabel_y = "Frecuencia", 
                  my_fill = "Rehospitalización", 
                  my_angle = NULL,
                  my_legend = "right")

p10 <- mygeom_bar(mydata = data_rehosp, 
                  myexposure = "est_civil", 
                  myoutcome = "rehosp_oms", 
                  mytitle = "Estado civil", 
                  mylabel_x = "", 
                  mylabel_y = "Frecuencia", 
                  my_fill = "Rehospitalización", 
                  my_angle = NULL,
                  my_legend = "right")

grid.arrange(p9,
              p10,
              ncol = 1,
              nrow = 2)

```

<div style= "text-align:justify"></div>
Con el objetivo de enriquecer el análisis exploratorio, se calcularán dos medidas muy comúnes de la teoría de la información, éstas permiten inferir algo del poder predictivo que pueden tener las variables independientes, antes de hacer parte de un modelo.</div>

[Volver al Índice](#indice)</div>

<hr>
<h2 id="AnalisisWOE" style="text-align: center;" markdown ="1">Análisis de clasificación binaria usando WOE y el IV</h2>
<div style="text-align: justify">

El peso de la evidencia (WOE) y el valor de la información (IV) ayudan, entre otras cosas, a determinar la contribución independiente de cada variable al resultado, y detectar relaciones lineales y no lineales. El WOE mide la relación entre la variable predictiva y el objeto binario, mientras que el IV mide la fuerza predictiva de esa relación.

La tabla a continuación contiene los valores del "valor de la información" con y sin el ajuste derivado de la validación cruzada. Cuando se realiza el ajuste con el objetivo de que los resultados sean más estables, tanto pago del diagnóstico, el hecho de que el paciente halla pasado por la Unidad de cuidados, y si fueron realizados procedimientos quirúrgicos serán las únicas variables con suficiente capacidad de predicción a nivel individual y univariable (Iv > 0.05). Cuando se relaja el supuesto, IV sin restar el penalty, se incluirían los días en que estuvo hospitalizado.</div>

```{r, message = FALSE, warning = FALSE, echo = FALSE, eval =TRUE}
set.seed(1234)
data_rehosp <- data_rehosp %>%
  mutate(id = 1:nrow(.)) 

data_rehosp %>%
  sample_frac(size = .70) -> train

data_rehosp %>%
  anti_join(x = .,
            y = train, 
            by = "id") -> test
  
train <- select(.data = train, -id)
test <- select(.data = test, -id)

IV <- create_infotables(data = train,
                   valid = test,
                   y = "rehosp_oms")

kable_styling(kable(IV$Summary), 
              position = "center", 
              row_label_position = 1,
              full_width = F)
```
<div style= "text-align:justify">
De acuerdo al poder predictivo de cada una de las variables, se eligen aquellas cuyo Valor de la informaciÓn (IV) sea superior al 2% (0,02). Las variables con IV inferiores a este valor se consideran impredictivas y se decide descartarlas. Las variables que continuan, en orden de relevancia segun su poder predictor, son:

<ul>
<li>pago_hosp</li>
<li>quirur</li>
<li>dias_uce</li>
<li>dias_uci</li>
<li>proveedor</li>
<li>dias_hosp</li>
<li>edad</li>
<li>genero</li>
<li>ciudad</li>
</ul>


Sin embargo, tanto la ciudad, como el proveedor no serán tenidos en cuenta, por que pueden llegar a condicionar nuestra variable objetivo. Adicionalmente, lo días UCE y UCI parecen estar altamente correlacionados con la variable objetivo, generando una sobrepredicción. Se evalúa ademas las condiciones que permiten generar estas dos ultimas variables encontrando que solo se almacenan cuando el valor pagado hasta el momento es cero; por todo esto estas dos variables tampoco serán tenidas en cuenta.

Enfocandonos en el pago del diagnóstico, el cual, es una de las variables con mayor influencia, el WOE nos indica una relación no lineal, con un incremento en el WOE a medida que disminuye el rango de pago en el diagnóstico.</div>

```{r, message = FALSE, warning = FALSE, echo = FALSE, eval =TRUE}
kable_styling(kable(IV$Tables$pago_hosp), 
              position = "center", 
              row_label_position = 1,
              full_width = F)
```

```{r, message = FALSE, warning = FALSE, echo = FALSE, eval =TRUE}
n <- names(IV$Tables)
for (i in 1:length(n)){
   plot_infotables(IV, n[i])}

MultiPlot(IV, IV$Summary$Variable[c(1,2,3,4,6,10)])
```

[Volver al Índice](#indice)</div>

<hr>
<h2 id="Modelo" style="text-align: center;" markdown="1">Modelo</a></h2>
<div style = "text-align: justify">

El objetivo principal del análisis es estimar un modelo predictivo con el cuál se pueda estimar la probabilidad de que un paciente termine en una rehospitalización, asociada a un diangóstico anterior. Para ello se empleará un modelo de regresión logística, el cuál es ampliamente utilizado para resolver problemas de clasificación binaria.

Una vez se realizan los filtros de calidad y completitud, y tras lo obtenido en los resultados del WOE, se procede a realizar la seleccion de variables para el modelo. Se tendrán en cuenta entonces, el pago realizado, los días en que estuvo el paciente de forma general, el hecho de que se le haya realizado o no una cirugía, el género, la edad y el estrato.

Para evaluar la capacidad de generalización del modelo, se dividirá el conjunto de datos en entrenamiento (70%) y prueba (30%).

También vamos a escalar nuestras variables numericas, debido a que tenemos unos valores muy altos en el pago de la hospitalización los cuales pueden generar influencias en el modelo hacia esta variable.</div>

```{r, message = FALSE, warning = FALSE, echo = FALSE, eval =TRUE}
set.seed(1234)

data_rehosp %>%
  select(id,
        pago_hosp,
        quirur,
        dias_hosp,
        genero,
        edad,
        estrato,
        rehosp_oms) -> model_rehosp

model_rehosp %>%
  sample_frac(size = 0.7) -> training

model_rehosp %>%
  anti_join(x = .,
            y = training,
            by = "id") -> testing

testing %>%
  select(-id) -> testing

training %>%
  select(-id) %>%
  mutate(rehosp_oms = as.factor(rehosp_oms)) -> training

#training <- training %>% mutate_each_(funs(scale(.) %>% as.vector),           vars=c("pago_hosp","dias_hosp")) 

```

[Volver al Índice](#indice)</div>

<hr>
<h3 id="SMOTE" style="text-align: center;" markdown="1">Smote</h3>
<div style="text-align: justify">

Como se habia mencionado anteriormente, la informacion se encuentra desbalanceada; esto es, teniendo en cuenta que el problema en que se esta trabajando consiste en la clasificacion de una variable dicotómica, se debe analizar el nivel de representacion de sus posibles valores dentro del conjunto total de datos.</div>

```{r, message = FALSE, warning = FALSE, echo = FALSE, eval =TRUE}

kable(as.data.frame(prop.table(table(model_rehosp$rehosp_oms)))) %>%
kable_styling(position = "center", 
              row_label_position = 1,
              full_width = F) %>%
row_spec(0,background="#EBF0F7")

```

<div style="text-align: justify">
Vemos que la representacion para la categoría positiva es un poco mas del 2% de la información. En este caso vamos a realizar un tratamiento que permita aumentar la clase minoritaria, sin utilizar soluciones genéricas como reducir la clase mayoritaria al nivel de la clase menor.

Para ello, vamos a utilizar la técnica SMOTE (Synthetic Minority Oversampling Method), la cual genera nuevas instancias artificiales de la clase más pequeña interpolando los valores de las instancias minoritarias más cercanas a una dada.

Por medio de SMOTE se generará un nuevo set de datos de entrenamiento, en el cual se tenga un 60% de informacion para la categoria negativa (rehosp_oms = 0) y 40% para la categoria positiva (rehosp_oms = 0).</div>

```{r, message = FALSE, warning = FALSE, echo = FALSE, eval =TRUE}
training <- SMOTE(rehosp_oms ~ ., as.data.frame(training), perc.over = 350, perc.under = 150)
#training <- SMOTE(rehosp_oms ~ ., as.data.frame(training), perc.over = 300, perc.under = 200)
```

Verificamos que el set de entrenamiento se encuentre balanceado:

```{r, message = FALSE, warning = FALSE, echo = FALSE, eval =TRUE}

kable_styling(kable(as.data.frame(prop.table(table(training$rehosp_oms)))), 
              position = "center", 
              row_label_position = 1,
              full_width = F) %>%
row_spec(0,background="#EBF0F7")

```

[Volver al Índice](#indice)</div>

<hr>
<h3 id="Ajustemod" style="text-align: center;" markdown="1">Ajuste del modelo y Estimación de parámetros</h3>
<div style="text-align: justify">

Del resultado exploratorio anterior, al discriminar el análisis de las variables independientes por nuestra variable objetivo (Rehospitalización), es posible evidenciar una diferencia clara entre las distribuciones para los atributos: Pago/costo del procedimiento y los días en que el usuario estuvo internado ya sea en la Unidad de Cuidados Intensivos o Especiales. Esto podría ser un indicio de que estas variables en particular, pueden llegar a ser relevantes para explicar la probabilidad de ocurrencia del evento, es decir, cuando hubo una hospitalización posterior ligada a un diagnóstico.

A continuación, al ajustar el modelo obtenemos los siguientes resultados:</div>

```{r, message = FALSE, echo = FALSE, eval =TRUE}
rm(list=ls()[!ls() %in% c("training", "testing", "data_rehosp")])
mylogit <- glm(rehosp_oms ~ pago_hosp + quirur + dias_hosp + edad + genero + estrato, data = training, family = "binomial")
summary(mylogit)
```

<div style="text-align: justify"></div>
1. Cada cambio en una unidad en el pago hospitalario disminuirá las probabilidades de rehospitalización, pero en una cantidad muy pequeña (-6.953E-08)
2. Cuando a un paciente se le realizó un procedimiento quirúrgico su probabilidad de que termine hospitalizado de nuevo por el mismo diagnóstico, disminuye en más del 19% en comparación a cuando no se le realiza ninguna cirugía.

El resto de las variables no son suficientemente explicativas para predecir, de manera significativa, su efecto sobre la variable de respuesta binaria.

Después de estimados los coeficentes se procede a realizar la predicción dentro y fuera de muestra para evaluar la precisión (accuracy) y capacidad de generalización de nuestro modelo. </div>

```{r, message = FALSE, echo = FALSE, eval =TRUE}
pred_train <- predict(mylogit, newdata = training[-7], type = "response")
y_pred_train <- ifelse(pred_train > 0.5, 1, 0)
y_act_train <- training$rehosp_oms

pred = predict(mylogit, type = 'response', newdata = testing[-7])
y_pred = ifelse(pred > 0.5, 1, 0)
y_act <- testing$rehosp_oms

kable(data.frame(Train = mean(y_pred_train == y_act_train), Test = mean(y_pred == y_act))) %>%
  kable_styling(position = "center", 
                row_label_position = 1,
                full_width = F) %>%
row_spec(0,background="#EBF0F7")
  
```
<div style="text-align: justify"></div>
Los resultados indican un nivel de accuracy de 62% en los datos de entrenamiento y 63% en testing. Para ver en detalle como se comporta, al discriminar entre los casos en que el paciente sale definitivamente o termina en una rehospitalización, y evidenciar su desempeño por separado, se estimará la matriz de confusión:</div>

```{r}
table(as.matrix(testing[, 7]), y_pred > 0.5)
```

Resultados Curva de ROC:


```{r, message = FALSE, echo = FALSE, eval =TRUE}
library(ROCR)
ROCRpred = prediction(pred, testing$rehosp_oms)
 
# Performance function
ROCRperf = performance(ROCRpred, "tpr", "fpr")

perf1 <- performance(ROCRpred, "prec", "rec")
plot(perf1)
 
# Plot ROC curve
plot(ROCRperf, colorize=TRUE, print.cutoffs.at=seq(0,1,by=0.1), text.adj=c(-0.2,1.7))

```

###Regularizado

para la regularización se utilizará el paquete glmnet, el cual asigna un valor de alpha = 0 i es ridge y alpha = 1 si lasso. Antes de sumergirse en el código, vale la pena señalar lo siguiente:

* glmnet no tiene una interfaz de fórmula, por lo que uno tiene que ingresar los predictores como una matriz y las etiquetas de clase como un vector.

* no acepta predictores categóricos, por lo que uno tiene que convertirlos en valores numéricos antes de pasarlos a glmnet.

La función glmnet model.matrix crea la matriz y también convierte los predictores categóricos en variables ficticias apropiadas; mientras que se usará la función cv.glmnet , para encontra de manera automáticauna el valor óptimo de lambda.

```{r}
library(glmnet)
library(Matrix)
set.seed(123) 

x_train <- model.matrix(rehosp_oms~., training)[,-1]
y_train <- ifelse(training$rehosp_oms == "1", 1, 0)

##Hallando el mejor lambda
cv.lasso <- cv.glmnet(x_train, y_train, family = "binomial", type.measure = "mse", alpha = 1)
plot(cv.lasso)
```

La gráfica muestra que el registro del valor óptimo de lambda (es decir, el que minimiza el error cuadrático medio) es aproximadamente -3. El valor exacto se puede ver al examinar la variable lambda_min en el código a continuación. En general, sin embargo, el objetivo de la regularización es equilibrar la precisión y la simplicidad. En el contexto actual, esto significa un modelo con el menor número de coeficientes que también proporciona una buena precisión . 

```{r}
cv.lasso$lambda.min
```

En general, el propósito de la regularización es equilibrar la precisión y la simplicidad. Esto significa, un modelo con el menor número de predictores que también da una buena precisión. Para este fin, la función cv.glmnet() también encuentra el valor de lambda que proporciona el modelo más simple pero también se encuentra dentro de un error estándar del valor óptimo de lambda. Este valor se llama lambda.1se. Este valor de lambda ( lambda.1se) es lo que usaremos en el resto de la computación.


```{r}
cv.lasso$lambda.1se
```

```{r}
coef(cv.lasso, cv.lasso$lambda.min)
```

La salida muestra que solo aquellas variables que hemos determinado que son significativas en base a los valores de p tienen coeficientes distintos de cero, en este caso el pago hospitalario, todos los coeficientes de las demás variables han sido puestos a cero por el algoritmo.

Usando lambda.1secomo la mejor lambda, da los siguientes coeficientes de regresión:

```{r}
coef(cv.lasso, cv.lasso$lambda.1se)
```

Usando lambda.1se, los coeficiente de 4 variables se han establecido en cero mediante el algoritmo de lazo, reduciendo la complejidad del modelo.

La configuración de lambda = lambda.1se produce un modelo más simple en comparación con lambda.min, pero el modelo podría ser un poco menos preciso que el obtenido con lambda.min.

```{r}
##Lambda regression
std_ridge_logit <- glmnet(x_train, y_train, family="binomial", alpha=1)
SRL_pred_train <- predict(std_ridge_logit, x_train, type="class", s=cv.lasso$lambda.1se)

```

###Matriz training
```{r}
confusion_matrix_train <- table(y_train, SRL_pred_train)
confusion_matrix_train
```

```{r}
error_rate_train <- (760+920)/(760+920+1814+1368)
error_rate_train
```

###Matriz test
```{r}

x_test <- model.matrix(rehosp_oms~., testing)[,-1]
y_test <- ifelse(testing$rehosp_oms == 1, 1, 0)


```

```{r}
SRL_pred_test <- predict(std_ridge_logit, x_test, type="class", s=cv.lasso$lambda.1se)
confusion_matrix_test <- table(y_test, SRL_pred_test)
confusion_matrix_test
```

```{r}
error_rate_test <- (84+2867)/(7344+2867+84+129)
error_rate_test
```

Calculando el modelo con ridge:
```{r}
##Hallando el mejor lambda
cv.ridge <- cv.glmnet(x_train, y_train, family = "binomial", type.measure = "mse", alpha = 0)
coef(cv.ridge, cv.ridge$lambda.1se)
```

```{r}
SRR_pred_test <- predict(std_ridge_logit, x_test, type="class", s=cv.ridge$lambda.1se)
confusion_matrix_test <- table(y_test, SRR_pred_test)
confusion_matrix_test
```


[Volver al Índice](#indice)</div>

<hr>
<h3 id="Recomendacion" style="text-align: center;" markdown="1">Recomendaciones y Estrategias</h3>
<div style="text-align: justify">

Como se pudo observar en la definicion de la variable endógena de la rehospitalización, esta se construyó mediante dos restricciones en el set de datos inicial:
1. Que dentro de los siguientes 30 dias a la primera hospitalización surgiera una segunda hospitalizacion.
2. Que para aquellos casos donde hay dos eventos en la ventana de 30 días, los códigos de diagnóstico CIE10 del primero y segundo evento pertenecieran a la misma categoría de diagóstico en la clasificación de la OMS.

En este sentido, tenemos dos condicionantes que se podrían ajustar, ya que restringen la posibilidad de encontrar un mayor numero de casos que se puedan considerar como rehospitalización; por ejemplo, algunos estudios sugieren que la ventana de tiempo podría ser de 15 dias entre el primer y segundo evento. En cuanto a la similitud de los diagnósticos de ambos eventos, para este modelo se tuvo en cuenta solo si ambos diagnósticos pertenecen a la misma categoría, sin embargo es importante tener en cuenta que hay diagnósticos que pueden desencadenar en otros que no necesariamente sean de la misma categoría. Este tipo de asociaciones requieren de un mayor análisis a nivel médico.

Se han descrito factores asociados con la rehospitalizacion relacionados con la calidad de vida de los pacientes, sin embargo en este modelo no se incluyo gran parte de este tipo de informacion, ya que, desde el principio, la población objetivo se compone de individuos asegurados en poliza de vida y salud, en su mayoria, de estrato cuatro hacia arriba. De esta forma ya no aporta información medir el nivel de calidad de vida o falicidad de acceso a los servicios de salud, pero se podria tener en cuenta información relacionada con sintomas depresivos.

La calidad en el cuidado hospitalario tambien se ha considerado como un factor importante, por lo tanto se podría considerar la agregación de  información que indique que tan óptimas son las condiciones para una buena atención en los centros hospitalarios y lugares que se tuvieron en cuenta.</div>

```{r}
# PASO 1:   Carga Package y Set de datos
# ---------------------------------------------------------------------------
library(C50)
library(rpart)
library(rpart.plot) 
data(churn); # carga tablas

# PASO 2:   Crea Arbol de Decision
# ---------------------------------------------------------------------------
ModeloArbol <- rpart(rehosp_oms ~ ., data = training, parms=list(split="information"))

# PASO 3:  Predice rehospitalizacion en datos de TEST
# ---------------------------------------------------------------------------
Prediccion <- predict(ModeloArbol, testing, type="class") # Predicción en Test
MC         <- table(testing$rehosp_oms, Prediccion) # Matriz de Confusión

MC
# PASO 4: Crea Grafico
# ---------------------------------------------------------------------------
rpart.plot(ModeloArbol, type=1, extra=100,cex = .7,  box.col=c("gray99", "gray88")[ModeloArbol$frame$yval])
```


```{r}
library(e1071)

# Ejecución del modelo SVM
modelosvm <- svm(rehosp_oms ~ ., data = training)

# Predicción de los restantes
prediccionsvm <- predict(modelosvm, new = testing)

# Tabla de confusión.
# Se usa with para que aparezca el nombre de la variable Species en ella
# ya que en caso contrario no sale.
(mc <- with(testing,(table(prediccionsvm, rehosp_oms))))


# % correctamente clasificados
(correctos <- sum(diag(mc)) / nrow(testing) *100)


```


```{r}
library(ipred)

# Ejecución del modelo de Bagging
modelobag <- bagging(rehosp_oms~., data=training)

# Resumen del ajuste del modelo
#modelo
## 
## Bagging classification trees with 25 bootstrap replications 
## 
## Call: bagging.data.frame(formula = Species ~ ., data = datos.entreno)
# Hacer predicciones
prediccionbag <- predict(modelobag, testing)

# Matriz de confusión
(mc <- with(testing,table(prediccionbag, rehosp_oms)))


```


```{r}
# Carga el paquete específico del método Random Forest
library(randomForest)

# Ajustar modelo
modeloRForest <- randomForest(rehosp_oms~., data=training)

# Resumen del ajuste del modelo
#modelo

prediccionRForest <- predict(modeloRForest, testing)

# Matriz de confusión
(mc <- with(testing, table(prediccionRForest, rehosp_oms)))

```