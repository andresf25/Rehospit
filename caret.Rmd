---
title: "R Notebook"
output: html_notebook
---

```{r, message = FALSE, echo = FALSE, eval =TRUE, warning=FALSE}
rm(list = ls())
library(pROC)
library(caret)
library(rpart)
library(randomForest)
library(e1071)
library(purrr)
library(dplyr)
load("data_rehosp.rda")
```

Seleccionando variables del WOE:

```{r, message = FALSE, echo = FALSE, eval =TRUE, warning=FALSE}
data_rehosp %>%
  select(-marcas,
         -id,
         -ramo,
         -est_civil,
         -dias_uci,
         -dias_uce) -> model_rehosp

```

Dividiendo la información en validación (70) y prueba (30)

```{r, message = FALSE, echo = FALSE, eval =TRUE, warning=FALSE}
set.seed(1234)
index <- createDataPartition(model_rehosp$rehosp_oms, p = 0.70, list = FALSE)
train <- model_rehosp[ index,]
test <- model_rehosp[-index,]
```

Después de dividirse la data en entrenamiento y teniendo en cuenta que hay columnas numéricas con unidades de valor muy extremos, se procede a escalar las variables.

```{r, message = FALSE, echo = FALSE, eval =TRUE, warning=FALSE}
preProcValues <- preProcess(train, method = c("center", "scale"))

trainTransformed <- predict(preProcValues, train)
testTransformed <- predict(preProcValues, test)

trainTransformed$rehosp_oms <- relevel(as.factor(train$rehosp_oms), "1")
testTransformed$rehosp_oms <- relevel(as.factor(test$rehosp_oms), "1")

levels(trainTransformed$rehosp_oms) <- c("si", "no")
levels(testTransformed$rehosp_oms) <- c("si", "no")



```

Inicialmente se utilizará una máquina de aumento de gradiente (gbm), ya que puede manejar fácilmente las posibles interacciones y no linealidades que se han simulado anteriormente. Los hiperparámetros del modelo se ajustan mediante validación cruzada repetida en el conjunto de entrenamiento, repitiendo cinco veces con diez pliegues utilizados en cada repetición.

```{r, message = FALSE, echo = FALSE, eval =TRUE, warning=FALSE}
ctrl <- trainControl(method = "repeatedcv",
                     number = 10,
                     repeats = 5,
                     summaryFunction = twoClassSummary,
                     classProbs = TRUE)

set.seed(5627)

orig_fit <- train(rehosp_oms ~ .,
                  data = trainTransformed,
                  method = "gbm",
                  verbose = FALSE,
                  metric = "sens",
                  trControl = ctrl)
```

Observando la matriz de confusión:

```{r}
confusionMatrix(reference = testTransformed$rehosp_oms, 
                predict(orig_fit, 
                        newdata = testTransformed))
```

El desequilibrio en los datos, hace que el modelo sólo pueda predecir bien la clase minoritaria, por tanto, se empleará SMOTE como técnica de rebalanceo para incrementar con valores sintéticos el número de eventos raros (rehospitalizaciones)

Compararémos el resultado anterior con el Gradient Boosting balanceado, un Árbol de Decisión, un Random Forest y una Máquina de Soporte Vectorial Radial, los cuales utilizan un límite de decisión no lineal.

```{r, message = FALSE, echo = FALSE, eval =TRUE, warning=FALSE}

trainTransformed <- SMOTE(rehosp_oms ~ ., as.data.frame(trainTransformed), perc.over = 350, perc.under = 150)

set.seed(5627)

ctrl$sampling <- "smote"


smote_fit <- train(rehosp_oms ~ .,
                   data = trainTransformed,
                   method = "gbm",
                   verbose = FALSE,
                   metric = "sens",
                   trControl = ctrl)

model_rf <- train(rehosp_oms ~., 
                  data = trainTransformed,
                  method = "rf", 
                  metric = "sens",
                  trControl = ctrl)

model_svm <- train(rehosp_oms ~., 
                  data = trainTransformed,
                  method = "svmRadial", 
                  metric = "sens",
                  trControl = ctrl)

model_svmpol <- train(rehosp_oms ~., 
                  data = trainTransformed,
                  method = "svmPoly", 
                  metric = "sens",
                  trControl = ctrl)

model_dt <- train(rehosp_oms ~., 
                  data = trainTransformed,
                  method = "rpart",
                  metric = "sens",
                  trControl = ctrl)
```

Obteniendo AUC para los 4 modelos:

```{r, message = FALSE, echo = FALSE, eval =TRUE, warning=FALSE}
model_list <- list(GBM = orig_fit,
                   GBM_SMOTE = smote_fit,
                   Random = model_rf,
                   SVMRadial = model_svm,
                   SVMPoly = model_svmpol,
                   Tree = model_dt)

model_list_roc <- model_list %>%
  map(test_roc, data = testTransformed, 
      variable = "rehosp_oms",
      positive_class = "si" )

model_list_roc %>%
  map(sens)
```

Podemos examinar la curva ROC real para tener una mejor idea de dónde los modelos ponderados y de muestreo están superando o no, al modelo original en una variedad de umbrales de clasificación.

Una de las ventajas de la curva ROC no depende de la distribución de clase, lo que lo hace útil para evaluar clasificadores que predicen eventos raros como enfermedades o desastres. Por el contrario, la evaluación del rendimiento utilizando la precisión (TP + TN) / (TP + TN + FN + FP) favorecería a los clasificadores que siempre predicen un resultado negativo para la clase minoritaria.

```{r, message = FALSE, echo = FALSE, eval =TRUE, warning=FALSE}
results_list_roc <- list(NA)
num_mod <- 1

for(the_roc in model_list_roc){
  
  results_list_roc[[num_mod]] <- 
    data.frame(TPR = the_roc$sensitivities,
               FPR = 1 - the_roc$specificities,
               Modelos = names(model_list)[num_mod])
  
  num_mod <- num_mod + 1
  
}

results_df_roc <- bind_rows(results_list_roc)

# Curva de ROC para los 4 modelos
custom_col <- c("#7FFFD4", "#32CD32", "#00BFFF", "#008B8B", "#00008B", "#4169E1")

ggplot(aes(x = FPR,  
           y = TPR, 
           group = Modelos), 
       data = results_df_roc) +
  geom_line(aes(color = Modelos), size = 1) +
  scale_color_manual(values = custom_col) +
  geom_abline(intercept = 0, slope = 1, color = "gray", size = 1) +
  theme_minimal()+
  ggtitle("Curvas de ROC")+
  theme(plot.title = element_text(hjust = 0.5))

```

Aquí, vemos que el modelo original parece dominar a los demás, el cual encuentra entre una tasa de falsos positivos entre el 0% y el 70%.

Después de obtenido el mejor modelo, vamos a realizar un ajuste en los hiperparámetros empleando Grid para identificar la combinación más optima. En lugar de especificar los valores exactos para cada parámetro de ajuste, podemos pedirle que utilice cualquier número de valores posibles para cada parámetro de ajuste a través de tuneLength, que se fijará en 10.

```{r}

set.seed(5627)

orig_opt <- train(rehosp_oms ~ .,
                  data = trainTransformed,
                  method = "gbm",
                  verbose = FALSE,
                  metric = "ROC",
                  trControl = ctrl, 
                  tuneLength = 10)
print(orig_opt)
```


```{r}
plot(orig_opt)
```

```{r}
confusionMatrix(reference = testTransformed$rehosp_oms, predict(orig_fit, newdata = testTransformed), positive = "si")
```

```{r}

confusionMatrix(reference = testTransformed$rehosp_oms, predict(model_dt, newdata = testTransformed), positive = "si")

# smote_fit,
#                    Random = model_rf,
#                    SVMRadial = model_svm,
#                    SVMPoly = model_svmpol,
#                    Tree = model_dt)
```
 
```{r}
roc_p <- roc(response = testTransformed$rehosp_oms,
             predictor = predict(orig_fit, newdata = testTransformed, type = "prob")[, "si"], 
             levels= rev(levels(testTransformed$rehosp_oms)))

predicted = predict(orig_fit, newdata = testTransformed, type = "prob")[, "si"]

predicted <- as.data.frame(testTransformed$rehosp_oms, c(predicted))

class(predicted)
class(testTransformed$rehosp_oms)

str(predicted)
plot(roc_p, print.thres = "best")
plot_pred_type_distribution (df = predicted, threshold = 0.7)
```
 
 