---
title: "R Notebook"
output: html_notebook
---

```{r, message = FALSE, echo = FALSE, eval =TRUE, warning=FALSE}
rm(list = ls())
library(pROC)
library(caret)
library(rpart)
library(randomForest)
library(e1071)
library(purrr)
library(dplyr)
load("data_rehosp.rda")
```

Seleccionando variables del WOE:

```{r, message = FALSE, echo = FALSE, eval =TRUE, warning=FALSE}
data_rehosp %>%
  select(-marcas,
         -id,
         -ramo,
         -est_civil,
         -dias_uci,
         -dias_uce) -> model_rehosp

```

Conviertiendo todas las variables categóricas en números:

```{r, message = FALSE, echo = FALSE, eval =TRUE, warning=FALSE}
# dmy <- dummyVars(" ~ .", data = model_rehosp, fullRank = T)
# rehosp_transform <- data.frame(predict(dmy, newdata = model_rehosp))
# rehosp_transform$rehosp_oms<-as.factor(rehosp_transform$rehosp_oms)
```

Dividiendo la información en validación (70) y prueba (30)

```{r, message = FALSE, echo = FALSE, eval =TRUE, warning=FALSE}
set.seed(1234)
index <- createDataPartition(model_rehosp$rehosp_oms, p = 0.70, list=FALSE)
train <- model_rehosp[ index,]
test <- model_rehosp[-index,]
```

```{r, message = FALSE, echo = FALSE, eval =TRUE, warning=FALSE}
str(trainTransformed)
```


Después de dividirse la data en entrenamiento y teniendo en cuenta que hay columnas numéricas con unidades de valor muy extremos, se procede a escalar las variables

```{r, message = FALSE, echo = FALSE, eval =TRUE, warning=FALSE}
preProcValues <- preProcess(train, method = c("center", "scale"))

trainTransformed <- predict(preProcValues, train)
testTransformed <- predict(preProcValues, test)

trainTransformed$rehosp_oms <- as.factor(train$rehosp_oms)
testTransformed$rehosp_oms <- as.factor(test$rehosp_oms)

levels(trainTransformed$rehosp_oms) <- c("no", "si")
levels(testTransformed$rehosp_oms) <- c("no", "si")

```

Inicialmente se utilizará una máquina de aumento de gradiente (gbm), ya que puede manejar fácilmente las posibles interacciones y no linealidades que se han simulado anteriormente. Los hiperparámetros del modelo se ajustan mediante validación cruzada repetida en el conjunto de entrenamiento, repitiendo cinco veces con diez pliegues utilizados en cada repetición.

```{r, message = FALSE, echo = FALSE, eval =TRUE, warning=FALSE}
ctrl <- trainControl(method = "repeatedcv",
                     number = 10,
                     repeats = 5,
                     summaryFunction = twoClassSummary,
                     classProbs = TRUE)

set.seed(5627)

orig_fit <- train(rehosp_oms ~ .,
                  data = trainTransformed,
                  method = "gbm",
                  verbose = FALSE,
                  metric = "ROC",
                  trControl = ctrl)
```

El AUC se utilizará para evaluar el clasificador para evitar tener que tomar decisiones sobre el umbral de clasificación.

```{r, message = FALSE, echo = FALSE, eval =TRUE, warning=FALSE}
test_roc <- function(model, data) {
  
  roc(data$rehosp_oms,
      predict(model, data, type = "prob")[, "si"])

}

orig_fit %>%
  test_roc(data = testTransformed) %>%
  auc()
```

Ahora utilizando métodos de muestreo (SMOTE)

```{r, message = FALSE, echo = FALSE, eval =TRUE, warning=FALSE}
ctrl$sampling <- "smote"

smote_fit <- train(rehosp_oms ~ .,
                   data = trainTransformed,
                   method = "gbm",
                   verbose = FALSE,
                   metric = "ROC",
                   trControl = ctrl)
```

Balanceo con Árbol de Decisión:

```{r, message = FALSE, echo = FALSE, eval =TRUE, warning=FALSE}
# ctrl$sampling <- "smote"
# 
# model_dt <- train(rehosp_oms ~., 
#                   data = trainTransformed,
#                   method = "rpart", 
#                   verbose = FALSE,
#                   metric = "ROC",
#                   trControl = ctrl)
```

Balanceo con Random Forest:

```{r, message = FALSE, echo = FALSE, eval =TRUE, warning=FALSE}
ctrl$sampling <- "smote"

model_rf <- train(rehosp_oms ~., 
                  data = trainTransformed,
                  method = "rf", 
                  verbose = FALSE,
                  metric = "ROC",
                  trControl = ctrl)
```

Balanceo con SVM:

```{r, message = FALSE, echo = FALSE, eval =TRUE, warning=FALSE}
ctrl$sampling <- "smote"

model_svm <- train(rehosp_oms ~., 
                  data = trainTransformed,
                  method = "svmRadial", 
                  verbose = FALSE,
                  metric = "ROC",
                  trControl = ctrl)
```

Obteniendo AUC para los 4 modelos:

```{r, message = FALSE, echo = FALSE, eval =TRUE, warning=FALSE}
model_list <- list(original = orig_fit,
                   SMOTE = smote_fit,
                   random = model_rf,
                   svm = model_svm)

model_list_roc <- model_list %>%
  map(test_roc, data = testTransformed)

model_list_roc %>%
  map(auc)
```

Podemos examinar la curva ROC real para tener una mejor idea de dónde los modelos ponderados y de muestreo están superando o no, al modelo original en una variedad de umbrales de clasificación. Aquí, vemos que el modelo original parece dominar a los demás, el cual encuentra entre una tasa de falsos positivos entre el 0% y el 70%.

```{r, message = FALSE, echo = FALSE, eval =TRUE, warning=FALSE}
results_list_roc <- list(NA)
num_mod <- 1

for(the_roc in model_list_roc){
  
  results_list_roc[[num_mod]] <- 
    data.frame(tpr = the_roc$sensitivities,
               fpr = 1 - the_roc$specificities,
               model = names(model_list)[num_mod])
  
  num_mod <- num_mod + 1
  
}

data
results_df_roc <- bind_rows(results_list_roc)

# Curva de ROC para los 4 modelos


custom_col <- c("#000000", "#009E73", "#0072B2", "#D55E00")

ggplot(aes(x = fpr,  y = tpr, group = model), data = results_df_roc) +
  geom_line(aes(color = model), size = 1) +
  scale_color_manual(values = custom_col) +
  geom_abline(intercept = 0, slope = 1, color = "gray", size = 1) +
  theme_bw(base_size = 18)

```


