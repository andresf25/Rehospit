---
title: "R Notebook"
output: html_notebook
---

```{r, message = FALSE, echo = FALSE, eval =TRUE, warning=FALSE}
rm(list = ls())
library(pROC)
library(caret)
library(rpart)
library(randomForest)
library(e1071)
library(purrr)
library(dplyr)
load("data_rehosp.rda")
```

Seleccionando variables del WOE:

```{r, message = FALSE, echo = FALSE, eval =TRUE, warning=FALSE}
data_rehosp %>%
  select(-marcas,
         -id,
         -ramo,
         -est_civil,
         -dias_uci,
         -dias_uce) -> model_rehosp

```

Dividiendo la información en validación (70) y prueba (30)

```{r, message = FALSE, echo = FALSE, eval =TRUE, warning=FALSE}
set.seed(1234)
index <- createDataPartition(model_rehosp$rehosp_oms, p = 0.70, list=FALSE)
train <- model_rehosp[ index,]
test <- model_rehosp[-index,]
```

Después de dividirse la data en entrenamiento y teniendo en cuenta que hay columnas numéricas con unidades de valor muy extremos, se procede a escalar las variables.

```{r, message = FALSE, echo = FALSE, eval =TRUE, warning=FALSE}
preProcValues <- preProcess(train, method = c("center", "scale"))

trainTransformed <- predict(preProcValues, train)
testTransformed <- predict(preProcValues, test)

trainTransformed$rehosp_oms <- as.factor(train$rehosp_oms)
testTransformed$rehosp_oms <- as.factor(test$rehosp_oms)

levels(trainTransformed$rehosp_oms) <- c("no", "si")
levels(testTransformed$rehosp_oms) <- c("no", "si")

```

Inicialmente se utilizará una máquina de aumento de gradiente (gbm), ya que puede manejar fácilmente las posibles interacciones y no linealidades que se han simulado anteriormente. Los hiperparámetros del modelo se ajustan mediante validación cruzada repetida en el conjunto de entrenamiento, repitiendo cinco veces con diez pliegues utilizados en cada repetición.

```{r, message = FALSE, echo = FALSE, eval =TRUE, warning=FALSE}
ctrl <- trainControl(method = "repeatedcv",
                     number = 10,
                     repeats = 5,
                     summaryFunction = twoClassSummary,
                     classProbs = TRUE)

set.seed(5627)

orig_fit <- train(rehosp_oms ~ .,
                  data = trainTransformed,
                  method = "gbm",
                  verbose = FALSE,
                  metric = "ROC",
                  trControl = ctrl)
```

El AUC se utilizará para evaluar el clasificador para evitar tener que tomar decisiones sobre el umbral de clasificación.

```{r, message = FALSE, echo = FALSE, eval =TRUE, warning=FALSE}

orig_fit %>%
  test_roc(data = testTransformed, 
           variable = "rehosp_oms", 
           positive_class = "si") %>%
  auc()
```

Ahora utilizando métodos de muestreo (SMOTE), compararémos el resultado anterior con el Gradient Boosting balanceado, un Árbol de Decisión, un Random Forest y una Máquina de Soporte Vectorial Radial, los cuales utilizan un límite de decisión no lineal.

```{r, message = FALSE, echo = FALSE, eval =TRUE, warning=FALSE}

set.seed(5627)

ctrl$sampling <- "smote"


smote_fit <- train(rehosp_oms ~ .,
                   data = trainTransformed,
                   method = "gbm",
                   verbose = FALSE,
                   metric = "ROC",
                   trControl = ctrl)

model_rf <- train(rehosp_oms ~., 
                  data = trainTransformed,
                  method = "rf", 
                  metric = "ROC",
                  trControl = ctrl)

model_svm <- train(rehosp_oms ~., 
                  data = trainTransformed,
                  method = "svmRadial", 
                  metric = "ROC",
                  trControl = ctrl)

model_svmpol <- train(rehosp_oms ~., 
                  data = trainTransformed,
                  method = "svmPoly", 
                  metric = "ROC",
                  trControl = ctrl)

model_dt <- train(rehosp_oms ~., 
                  data = trainTransformed,
                  method = "rpart",
                  metric = "ROC",
                  trControl = ctrl)
```

Obteniendo AUC para los 4 modelos:

```{r, message = FALSE, echo = FALSE, eval =TRUE, warning=FALSE}
model_list <- list(GBM = orig_fit,
                   GBM_SMOTE = smote_fit,
                   Random = model_rf,
                   SVMRadial = model_svm,
                   SVMPoly = model_svmpol,
                   Tree = model_dt)

model_list_roc <- model_list %>%
  map(test_roc, data = testTransformed, 
      variable = "rehosp_oms",
      positive_class = "si")

model_list_roc %>%
  map(auc)
```

Podemos examinar la curva ROC real para tener una mejor idea de dónde los modelos ponderados y de muestreo están superando o no, al modelo original en una variedad de umbrales de clasificación. Aquí, vemos que el modelo original parece dominar a los demás, el cual encuentra entre una tasa de falsos positivos entre el 0% y el 70%.

```{r, message = FALSE, echo = FALSE, eval =TRUE, warning=FALSE}
results_list_roc <- list(NA)
num_mod <- 1

for(the_roc in model_list_roc){
  
  results_list_roc[[num_mod]] <- 
    data.frame(TPR = the_roc$sensitivities,
               FPR = 1 - the_roc$specificities,
               Modelos = names(model_list)[num_mod])
  
  num_mod <- num_mod + 1
  
}

results_df_roc <- bind_rows(results_list_roc)

# Curva de ROC para los 4 modelos
custom_col <- c("#7FFFD4", "#32CD32", "#00BFFF", "#008B8B", "#00008B")

ggplot(aes(x = fpr,  
           y = tpr, 
           group = model), 
       data = results_df_roc) +
  geom_line(aes(color = model), size = 1) +
  scale_color_manual(values = custom_col) +
  geom_abline(intercept = 0, slope = 1, color = "gray", size = 1) +
  theme_minimal()+
  ggtitle("Curvas de ROC")+
  theme(plot.title = element_text(hjust = 0.5))

```

Después de obtenido el mejor modelo, vamos a realizar un ajuste en los hiperparámetros empleando Grid para identificar la combinación más optima. En lugar de especificar los valores exactos para cada parámetro de ajuste, podemos pedirle que utilice cualquier número de valores posibles para cada parámetro de ajuste a través de tuneLength, que se fijará en 10.

```{r}

set.seed(5627)

orig_opt <- train(rehosp_oms ~ .,
                  data = trainTransformed,
                  method = "gbm",
                  verbose = FALSE,
                  metric = "ROC",
                  trControl = ctrl, 
                  tuneLength = 10)
print(orig_opt)
```

```{r}
plot(orig_opt)
```

```{r}
confusionMatrix(predict(orig_fit,tes$Cos.code),dataset$Cos.code)
```

